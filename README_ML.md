# ğŸ§  Machine Learning en el Analizador de Algoritmos

## DescripciÃ³n
Este mÃ³dulo integra una red neuronal que aprende a clasificar algoritmos basÃ¡ndose en caracterÃ­sticas extraÃ­das del cÃ³digo fuente, mejorando significativamente la precisiÃ³n del anÃ¡lisis de complejidad temporal.

## CaracterÃ­sticas

### ğŸ”§ Red Neuronal
- **Arquitectura**: Red neuronal densa con 3 capas ocultas
- **Entrada**: 15 caracterÃ­sticas extraÃ­das del cÃ³digo
- **Salida**: ClasificaciÃ³n en 8 categorÃ­as de complejidad
- **OptimizaciÃ³n**: Adam optimizer con early stopping

### ğŸ“Š CaracterÃ­sticas ExtraÃ­das
1. `num_loops` - NÃºmero de bucles
2. `num_nested_loops` - Bucles anidados
3. `max_nesting_level` - Nivel mÃ¡ximo de anidamiento
4. `num_recursive_calls` - Llamadas recursivas
5. `num_conditionals` - Estructuras condicionales
6. `num_assignments` - Asignaciones
7. `num_function_calls` - Llamadas de funciÃ³n
8. `code_length` - Longitud del cÃ³digo
9. `num_variables` - Variables declaradas
10. `has_sorting` - Algoritmos de ordenamiento
11. `has_search` - Algoritmos de bÃºsqueda
12. `has_math_operations` - Operaciones matemÃ¡ticas
13. `complexity_keywords` - Palabras clave de complejidad
14. `loop_patterns` - Patrones de bucles
15. `recursion_patterns` - Patrones de recursiÃ³n

## InstalaciÃ³n

### 1. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 2. Verificar instalaciÃ³n
```bash
python -c "import tensorflow as tf; print('TensorFlow:', tf.__version__)"
python -c "import sklearn; print('Scikit-learn:', sklearn.__version__)"
```

## Uso

### 1. Entrenar el Modelo

#### Entrenamiento bÃ¡sico:
```bash
python train_model.py
```

#### Entrenamiento personalizado:
```bash
python train_model.py --samples 200 --epochs 150 --batch-size 64 --test
```

#### ParÃ¡metros disponibles:
- `--samples`: Muestras por clase (default: 100)
- `--epochs`: NÃºmero de Ã©pocas (default: 100)
- `--batch-size`: TamaÃ±o del batch (default: 32)
- `--model-path`: Ruta para guardar el modelo
- `--test`: Ejecutar pruebas despuÃ©s del entrenamiento

### 2. Usar el Modelo en el Analizador

#### En el cÃ³digo:
```python
from core.analyzer import AlgorithmAnalyzer

# Con red neuronal
analyzer = AlgorithmAnalyzer(use_neural_network=True, model_path="models/algorithm_classifier")

# Sin red neuronal
analyzer = AlgorithmAnalyzer(use_neural_network=False)

# Habilitar/deshabilitar dinÃ¡micamente
analyzer.enable_neural_network("models/algorithm_classifier")
analyzer.disable_neural_network()
```

#### En la lÃ­nea de comandos:
```bash
# Usar con modelo entrenado
python main.py --file algoritmo.py --neural-model models/algorithm_classifier

# Usar solo anÃ¡lisis tradicional
python main.py --file algoritmo.py --no-neural
```

### 3. Generar Dataset Personalizado

```python
from ml.dataset_generator import DatasetGenerator

generator = DatasetGenerator()
dataset = generator.generate_training_dataset(samples_per_class=150)
stats = generator.get_dataset_statistics(dataset)
print(stats)
```

## Estructura del Proyecto ML

```
ml/
â”œâ”€â”€ __init__.py              # InicializaciÃ³n del mÃ³dulo
â”œâ”€â”€ neural_network.py        # Clasificador de red neuronal
â””â”€â”€ dataset_generator.py     # Generador de datasets

models/                      # Modelos entrenados
â”œâ”€â”€ algorithm_classifier_model.h5
â”œâ”€â”€ algorithm_classifier_metadata.json
â””â”€â”€ algorithm_classifier_metrics.json

train_model.py               # Script de entrenamiento
```

## MÃ©tricas de Rendimiento

### Dataset de Entrenamiento
- **Total de muestras**: 800 (100 por clase)
- **DistribuciÃ³n balanceada**: 8 clases de complejidad
- **Longitud promedio**: ~200 caracteres por algoritmo

### PrecisiÃ³n Esperada
- **PrecisiÃ³n en entrenamiento**: >95%
- **PrecisiÃ³n en validaciÃ³n**: >90%
- **Confianza promedio**: >85%

### Clases de Complejidad
1. **O(1)** - Constante
2. **O(log n)** - LogarÃ­tmica
3. **O(n)** - Lineal
4. **O(n log n)** - LinealÃ­tmica
5. **O(nÂ²)** - CuadrÃ¡tica
6. **O(nÂ³)** - CÃºbica
7. **O(2â¿)** - Exponencial
8. **O(n!)** - Factorial

## Ventajas del Machine Learning

### ğŸ¯ PrecisiÃ³n Mejorada
- Aprende patrones complejos no capturados por reglas
- Mejora con mÃ¡s datos de entrenamiento
- Adaptable a diferentes estilos de cÃ³digo

### ğŸ”„ Aprendizaje Continuo
- Se puede reentrenar con nuevos ejemplos
- Mejora la precisiÃ³n con el tiempo
- Adaptable a nuevos patrones

### ğŸ¤– AutomatizaciÃ³n
- Reduce la necesidad de reglas manuales
- Detecta patrones sutiles
- Escalable a nuevos lenguajes

## Limitaciones

### ğŸ“ Dependencia de Datos
- Requiere dataset de entrenamiento
- Calidad depende de ejemplos de entrenamiento
- Necesita reentrenamiento para nuevos patrones

### âš¡ Rendimiento
- MÃ¡s lento que anÃ¡lisis tradicional
- Requiere mÃ¡s recursos computacionales
- Dependencia de TensorFlow

### ğŸ” Interpretabilidad
- Menos interpretable que reglas tradicionales
- DifÃ­cil explicar decisiones especÃ­ficas
- Requiere anÃ¡lisis de importancia de caracterÃ­sticas

## Mejoras Futuras

### ğŸš€ CaracterÃ­sticas Adicionales
- AnÃ¡lisis semÃ¡ntico del cÃ³digo
- DetecciÃ³n de optimizaciones
- AnÃ¡lisis de memoria (complejidad espacial)

### ğŸ§  Arquitecturas Avanzadas
- Redes neuronales recurrentes (RNN)
- Transformers para anÃ¡lisis de cÃ³digo
- Modelos pre-entrenados

### ğŸ“Š Datasets Mejorados
- Datasets de cÃ³digo real
- MÃºltiples lenguajes de programaciÃ³n
- Anotaciones de expertos

## Troubleshooting

### Error: "No module named 'tensorflow'"
```bash
pip install tensorflow
```

### Error: "CUDA not available"
```bash
pip install tensorflow-cpu  # Para CPU only
```

### Error: "Model not found"
```bash
python train_model.py  # Entrenar modelo primero
```

### Baja precisiÃ³n
- Aumentar `--samples` (mÃ¡s datos)
- Aumentar `--epochs` (mÃ¡s entrenamiento)
- Verificar calidad del dataset

## Contribuir

1. **Agregar nuevos algoritmos** al `DatasetGenerator`
2. **Mejorar caracterÃ­sticas** en `AlgorithmClassifier`
3. **Optimizar arquitectura** de la red neuronal
4. **Crear datasets** de cÃ³digo real
5. **Documentar** nuevos patrones de complejidad 